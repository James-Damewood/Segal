{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "from torch import utils\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.cuda.set_device(1)\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "print (use_cuda)\n",
    "\n",
    "torch.backends.cudnn.enabled\n",
    "import os\n",
    "\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgcnn.data import CIFData\n",
    "from cgcnn.data import collate_pool\n",
    "from cgcnn.model import CrystalGraphConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms(symbols='Ag27', pbc=True, cell=[[0.0, 6.135, 6.135], [6.135, 0.0, 6.135], [6.135, 6.135, 0.0]], tags=..., calculator=Clease(...))\n"
     ]
    }
   ],
   "source": [
    "from ase import Atoms\n",
    "from ase.calculators.emt import EMT\n",
    "from ase.db import connect\n",
    "\n",
    "\n",
    "from clease.tools import update_db\n",
    "from clease import Concentration\n",
    "from clease import CEBulk\n",
    "from clease import Evaluate\n",
    "from clease import NewStructures\n",
    "from clease.calculator import Clease\n",
    "from clease.calculator import attach_calculator\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "k_b = 0.00008617\n",
    "\n",
    "def get_concentrations(lattices):\n",
    "    lattices = ((lattices+1)/2).view(lattices.shape[0],-1)\n",
    "    Ag_conc = torch.sum(lattices,dim=1)/(27)\n",
    "    return Ag_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms(symbols='Ag2PdAg2PdAgPdAg3Pd6AgPd3Ag4Pd2', pbc=True, cell=[[0.0, 6.135, 6.135], [6.135, 0.0, 6.135], [6.135, 6.135, 0.0]], tags=..., calculator=Clease(...))\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ase.io.trajectory import TrajectoryWriter\n",
    "from ase.io import read\n",
    "from ase.io import iread\n",
    "from ase.io import write\n",
    "\n",
    "lst = []\n",
    "for i in range(1):\n",
    "    name = 'batch_template_1/structure_num' + str(i) + '.cif'\n",
    "    for j in range(len(atoms.numbers)):\n",
    "        rd = np.random.rand()\n",
    "        if rd > 0.5:\n",
    "            atoms.numbers[j] = 46\n",
    "        else:\n",
    "            atoms.numbers[j] = 47\n",
    "    \n",
    "    print(atoms)\n",
    "    write(name,atoms)\n",
    "    \n",
    "    curr_entry = []\n",
    "    curr_entry.append('structure_num' + str(i))\n",
    "    curr_entry.append(0)\n",
    "    lst.append(curr_entry)\n",
    "    \n",
    "df = pd.DataFrame(lst)\n",
    "file = 'batch_template_1/id_prop.csv'\n",
    "df.to_csv(file, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading model params 'model_best_alt_new.pth.tar'\n",
      "=> loaded model params 'model_best_alt_new.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Crystal gated neural networks')\n",
    "parser.add_argument('modelpath', help='path to the trained model.')\n",
    "parser.add_argument('cifpath', help='path to the directory of CIF files.')\n",
    "parser.add_argument('-b', '--batch-size', default=1, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 100)')\n",
    "parser.add_argument('-j', '--workers', default=0, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 0)')\n",
    "parser.add_argument('--disable-cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "\n",
    "args = parser.parse_args(['model_best_alt_new.pth.tar','batch_template_1'])\n",
    "\n",
    "if os.path.isfile(args.modelpath):\n",
    "    print(\"=> loading model params '{}'\".format(args.modelpath))\n",
    "    model_checkpoint = torch.load(args.modelpath,\n",
    "                                  map_location=lambda storage, loc: storage)\n",
    "    model_args = argparse.Namespace(**model_checkpoint['args'])\n",
    "    print(\"=> loaded model params '{}'\".format(args.modelpath))\n",
    "else:\n",
    "    print(\"=> no model params found at '{}'\".format(args.modelpath))\n",
    "\n",
    "args.cuda = not args.disable_cuda and torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_template_1\n"
     ]
    }
   ],
   "source": [
    "print(args.cifpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/james_mlmat/lib/python3.7/site-packages/pymatgen/io/cif.py:1123: UserWarning: Issues encountered while parsing CIF: Some fractional co-ordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: %s\" % \"\\n\".join(self.warnings))\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFData('batch_template_1',radius = 12,max_num_nbr = 24)\n",
    "collate_fn = collate_pool\n",
    "test_loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                         num_workers=args.workers, collate_fn=collate_fn,\n",
    "                         pin_memory=args.cuda)\n",
    "\n",
    "structures, _, _ = dataset[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "energy_model = CrystalGraphConvNet(orig_atom_fea_len, nbr_fea_len,\n",
    "                            atom_fea_len=model_args.atom_fea_len,\n",
    "                            n_conv=model_args.n_conv,\n",
    "                            h_fea_len=model_args.h_fea_len,\n",
    "                            n_h=model_args.n_h,\n",
    "                            classification=True if model_args.task ==\n",
    "                            'classification' else False)\n",
    "if args.cuda:\n",
    "    energy_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_model.eval()\n",
    "\n",
    "for i, (input, target, batch_cif_ids) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        if args.cuda:\n",
    "            input_var = (Variable(input[0].cuda(non_blocking=True)),\n",
    "                         Variable(input[1].cuda(non_blocking=True)),\n",
    "                         input[2].cuda(non_blocking=True),\n",
    "                         [crys_idx.cuda(non_blocking=True) for crys_idx in input[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 92])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:1')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:1')\n",
      "torch.Size([27, 24, 61])\n",
      "torch.Size([27, 92])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "print(input_var[0].shape)\n",
    "ag_key = copy.deepcopy(input_var[0][0])\n",
    "ag_key = ag_key.view(1,92)\n",
    "ag_key_large = ag_key.expand(27,-1)\n",
    "pd_key = copy.deepcopy(input_var[0][15])\n",
    "pd_key = pd_key.view(1,92)\n",
    "pd_key_large = pd_key.expand(27,-1)\n",
    "print(ag_key_large[0,:])\n",
    "print(pd_key_large[0,:])\n",
    "\n",
    "print(input_var[1].shape)\n",
    "#print(input_var[1][0])\n",
    "#print(input_var[1][12499])\n",
    "\n",
    "#set_one = copy.deepcopy(input_var[1][0])\n",
    "print(ag_key_large.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = torch.mean(tensor)\n",
    "        self.std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_best_alt_new.pth.tar\n",
      "=> loading model 'model_best_alt_new.pth.tar'\n",
      "=> loaded model 'model_best_alt_new.pth.tar' (epoch 154, validation 1.5135937929153442)\n"
     ]
    }
   ],
   "source": [
    "print(args.modelpath)\n",
    "normalizer = Normalizer(torch.zeros(3))\n",
    "if os.path.isfile(args.modelpath):\n",
    "    print(\"=> loading model '{}'\".format(args.modelpath))\n",
    "    checkpoint = torch.load(args.modelpath,\n",
    "                            map_location=lambda storage, loc: storage)\n",
    "    energy_model.load_state_dict(checkpoint['state_dict'])\n",
    "    normalizer.load_state_dict(checkpoint['normalizer'])\n",
    "    print(\"=> loaded model '{}' (epoch {}, validation {})\"\n",
    "          .format(args.modelpath, checkpoint['epoch'],\n",
    "          checkpoint['best_mae_error']))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_energies(lattices):\n",
    "    \n",
    " \n",
    "    lattices.view(1,-1)\n",
    "    batch_size = lattices.shape[0]\n",
    "    lattices = lattices.view(-1)\n",
    "    size = lattices.shape[0]\n",
    "    ag_sites = torch.abs(((lattices + 1)/2).view(-1,1).expand(size,92))\n",
    "    pd_sites = (torch.abs(1 - lattices)/2).view(-1,1).expand(size,92)\n",
    "    \n",
    "    ids = torch.abs(ag_sites * ag_key_large + pd_sites * pd_key_large)\n",
    "    inp = (Variable(ids.cuda(non_blocking=True)),input_var[1],input_var[2],input_var[3])\n",
    "    energies = energy_model(*inp)\n",
    "    energies = normalizer.denorm(energies.data)\n",
    "    \n",
    "    return (27*energies).view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattices = torch.tensor([1.0,1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,-1.0,-1.0,1.0,-1.0,-1.0,-1.0,-1.0,-1.0,1.0,-1.0,-1.0,1.0,1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2076], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(get_graph_energies(lattices.view(-1,27)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monte_Carlo_Simulation():\n",
    "    \n",
    "    def __init__(self,dim,temps,fields,J=1,samples_per_temp=1000,Eq_steps = 100):\n",
    "        self.Dim = dim\n",
    "        self.temps = temps\n",
    "        self.fields = fields\n",
    "        self.J = J\n",
    "        self.samples_per_temp = samples_per_temp\n",
    "        self.Eq_steps = Eq_steps\n",
    "        self.Autocorr_steps = 27\n",
    "        \n",
    "    def get_conc(self,lattice):\n",
    "        conc = torch.sum(lattice)\n",
    "        return conc\n",
    "    \n",
    "    \n",
    "    def get_energy(self,lattice,fd,window=None,window_width = None):\n",
    "        int_energy = get_graph_energies(lattice)\n",
    "        conc = self.get_conc(lattice)\n",
    "        #print(fd)\n",
    "        return int_energy - fd*conc\n",
    "    \n",
    "    def MC_step(self,lattice,curr_energy,temp,fd,window = None, window_width = None):\n",
    "\n",
    "        x_pos = random.randint(0,26)\n",
    "        e_init = curr_energy\n",
    "        cand_lattice = torch.clone(lattice)\n",
    "        if cand_lattice[x_pos] == 1.0:\n",
    "            cand_lattice[x_pos] = -1.0\n",
    "        else:\n",
    "            cand_lattice[x_pos] = 1.0\n",
    "        \n",
    "        e_new = self.get_energy(cand_lattice,fd)\n",
    "        delta_e = e_new - e_init\n",
    "        \n",
    "        if delta_e < 0:\n",
    "            accepted_lattice = cand_lattice\n",
    "            curr_energy = curr_energy + delta_e\n",
    "        else:\n",
    "            prob = -(delta_e)/(k_b*temp)\n",
    "            samp = np.log(random.random())\n",
    "            if samp < prob:\n",
    "                accepted_lattice = cand_lattice\n",
    "                curr_energy = curr_energy + delta_e\n",
    "            else:\n",
    "                #print('here')\n",
    "                accepted_lattice = lattice\n",
    "        return accepted_lattice,curr_energy\n",
    "    \n",
    "    def initiate_lattice(self,window = None, window_width = None):\n",
    "        lattice = torch.zeros(27).cuda()\n",
    "        for i in range(27):\n",
    "            samp = random.random()\n",
    "            if samp < 0.5:\n",
    "                lattice[i] = 1.0\n",
    "            else:\n",
    "                lattice[i] = -1.0\n",
    "        return lattice\n",
    "    \n",
    "    def equilibrate(self,lattice,temp,fd,window = None,window_width = None):\n",
    "        for eq_time in range(self.Eq_steps):\n",
    "            lattice = self.get_lattice_sample(lattice,temp,fd,window,window_width)\n",
    "        return lattice\n",
    "    \n",
    "    def get_lattice_sample(self,lattice,temp,fd,window=None,window_width=None):\n",
    "        curr_energy = self.get_energy(lattice,fd,window,window_width)\n",
    "        for candidate in range(self.Autocorr_steps):\n",
    "            lattice,curr_energy = self.MC_step(lattice,curr_energy,temp,fd,window,window_width)\n",
    "        return lattice\n",
    "    \n",
    "    def run(self,start=None):\n",
    "        \n",
    "        energies = torch.zeros(len(self.temps),len(self.fields),self.samples_per_temp)\n",
    "        concs = torch.zeros(len(self.temps),len(self.fields),self.samples_per_temp)\n",
    "        for counter_t,temp in enumerate(self.temps):\n",
    "            if start is not None:\n",
    "                lattice = self.initiate_lattice(window=start,window_width=0.05)\n",
    "            else:\n",
    "                lattice = self.initiate_lattice()\n",
    "                \n",
    "            for counter_f,fd in enumerate(self.fields):\n",
    "                lattice = self.equilibrate(lattice,temp,fd)\n",
    "                #print('here')\n",
    "                for sample in range(self.samples_per_temp):\n",
    "                    lattice = self.get_lattice_sample(lattice,temp,fd)\n",
    "                    energies[counter_t,counter_f,sample] = self.get_energy(lattice,fd)\n",
    "                    concs[counter_t,counter_f,sample] = self.get_conc(lattice)\n",
    "                print(\"done\")\n",
    "        return energies,concs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2  -0.19 -0.18 -0.17 -0.16 -0.15 -0.14 -0.13 -0.12 -0.11 -0.1  -0.09\n",
      " -0.08 -0.07 -0.06 -0.05 -0.04 -0.03 -0.02 -0.01  0.    0.01  0.02  0.03\n",
      "  0.04  0.05  0.06  0.07  0.08  0.09  0.1   0.11  0.12  0.13  0.14  0.15\n",
      "  0.16  0.17  0.18  0.19  0.2 ]\n",
      "[250. 750.]\n"
     ]
    }
   ],
   "source": [
    "fields = np.linspace(-0.2,0.2,41)\n",
    "temps = np.linspace(250,750,2)\n",
    "print(fields)\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "Run_np = Monte_Carlo_Simulation(3,temps,fields)\n",
    "energies_np,concs_np = Run_np.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run_pn = Monte_Carlo_Simulation(3,temps,np.flip(fields))\n",
    "energies_pn,concs_pn = Run_pn.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 41, 1000])\n",
      "(2, 41)\n"
     ]
    }
   ],
   "source": [
    "print(concs_np.shape)\n",
    "concs_to_store = concs_np.mean(dim=2)\n",
    "concs_to_store = concs_to_store.cpu().detach().numpy()\n",
    "concs_to_store = (concs_to_store+27.0)/54\n",
    "print(concs_to_store.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"AgPd_CGC_np_new_250_750.csv\", concs_to_store, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.4068703e-05\n",
      "  0.0000000e+00 0.0000000e+00 1.4813741e-04 5.5556826e-04 3.9725927e-01\n",
      "  4.6966666e-01 5.2622223e-01 5.4607403e-01 5.6751853e-01 5.8648151e-01\n",
      "  6.0877776e-01 6.2799996e-01 6.5074074e-01 6.7100000e-01 6.9092596e-01\n",
      "  7.0714813e-01 7.2318524e-01 7.4203706e-01 7.6425928e-01 8.0325925e-01\n",
      "  8.5644448e-01 8.9388889e-01 9.1629630e-01 9.3244439e-01 9.4585186e-01\n",
      "  9.5733333e-01 9.6762961e-01 9.7814816e-01 9.8640740e-01 9.9266666e-01\n",
      "  9.9729627e-01]\n",
      " [1.0740845e-03 1.9629796e-03 1.9999964e-03 4.7036982e-03 5.4074042e-03\n",
      "  7.8148311e-03 1.0962945e-02 1.5407421e-02 2.0037051e-02 4.1037031e-02\n",
      "  8.1592597e-02 1.9285184e-01 3.3518520e-01 4.1855559e-01 4.5637038e-01\n",
      "  4.8666668e-01 5.1633334e-01 5.3359258e-01 5.5255556e-01 5.7274073e-01\n",
      "  5.8929628e-01 6.0670370e-01 6.2418520e-01 6.4270371e-01 6.5551847e-01\n",
      "  6.7599994e-01 6.9059259e-01 7.0637041e-01 7.2670370e-01 7.4340743e-01\n",
      "  7.6429629e-01 7.8414816e-01 8.1162959e-01 8.3848149e-01 8.6477774e-01\n",
      "  8.8555557e-01 9.0351856e-01 9.1803700e-01 9.2881477e-01 9.4018519e-01\n",
      "  9.4844443e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(concs_to_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:james_mlmat] *",
   "language": "python",
   "name": "conda-env-james_mlmat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
